
---

### **ضدالگو (Antipattern): واکشی بی‌رویه (Extraneous Fetching)**

ضدالگوها، نقص‌های رایج در طراحی هستند که می‌توانند در شرایط پرفشار (stress situations)، نرم‌افزار یا اپلیکیشن شما را دچار اختلال کنند و نباید نادیده گرفته شوند. در ضدالگوی «واکشی بی‌رویه»، برای انجام یک عملیات، داده‌های بیشتری از آنچه لازم است بازیابی می‌شود که اغلب منجر به سربار ورودی/خروجی (I/O overhead) غیرضروری و کاهش پاسخ‌دهی (responsiveness) سیستم می‌گردد.

#### **مثال‌هایی از ضدالگوی واکشی بی‌رویه**
این ضدالگو زمانی رخ می‌دهد که اپلیکیشن تلاش می‌کند با بازیابی تمام داده‌هایی که ممکن است به آن‌ها نیاز پیدا کند، درخواست‌های ورودی/خروجی را به حداقل برساند. این کار اغلب نتیجهٔ جبران افراطی برای ضدالگوی «ورودی/خروجی پُرگو» (Chatty I/O) است. برای مثال، ممکن است یک اپلیکیشن جزئیات تمام محصولات موجود در پایگاه داده را واکشی کند؛ در حالی که کاربر تنها به زیرمجموعه‌ای از این جزئیات نیاز دارد (برخی از آن‌ها ممکن است برای مشتریان اهمیتی نداشته باشند) و احتمالاً نیازی به دیدن همزمان همه محصولات ندارد. حتی اگر کاربر در حال مرور کل کاتالوگ باشد، منطقی‌تر است که نتایج صفحه‌بندی (paginate) شوند—برای مثال، هر بار ۲۰ محصول نمایش داده شود.

منشأ دیگر این مشکل، پیروی از شیوه‌های نادرست برنامه‌نویسی یا طراحی است. برای مثال، کد زیر با استفاده از Entity Framework، جزئیات کامل همه محصولات را واکشی می‌کند. سپس نتایج را فیلتر کرده تا تنها زیرمجموعه‌ای از فیلدها را برگرداند و بقیه را نادیده می‌گیرد.

در مثال بعدی، اپلیکیشن داده‌ها را برای انجام یک عملیات تجمعی (aggregation) بازیابی می‌کند که می‌توانست توسط خود پایگاه داده انجام شود. اپلیکیشن با دریافت تمام رکوردهای فروش و سپس محاسبه مجموع آن‌ها، کل فروش را حساب می‌کند.

مثال بعدی، مشکل ظریفی را نشان می‌دهد که ناشی از نحوه استفاده Entity Framework از LINQ to Entities است.

اپلیکیشن در تلاش است تا محصولاتی را پیدا کند که تاریخ `SellStartDate` آن‌ها بیش از یک هفته پیش بوده است. در اکثر موارد، LINQ to Entities یک عبارت `where` را به یک دستور SQL ترجمه می‌کند که توسط پایگاه داده اجرا می‌شود. اما در این مورد، LINQ to Entities نمی‌تواند متد `AddDays` را به SQL نگاشت کند. در عوض، تمام ردیف‌های جدول `Product` از پایگاه داده خوانده شده و نتایج در حافظه (in-memory) فیلتر می‌شوند.

فراخوانی متد `AsEnumerable` خود نشانه‌ای از وجود مشکل است. این متد نتایج را به یک اینترفیس `IEnumerable` تبدیل می‌کند. اگرچه `IEnumerable` از فیلتر کردن پشتیبانی می‌کند، اما این فیلترسازی در سمت کلاینت (client-side) انجام می‌شود، نه در پایگاه داده. به طور پیش‌فرض، LINQ to Entities از `IQueryable` استفاده می‌کند که مسئولیت فیلترسازی را به منبع داده واگذار می‌کند.

#### **چگونه ضدالگوی واکشی بی‌رویه را برطرف کنیم؟**

از واکشی حجم زیادی از داده‌ها که ممکن است به‌سرعت منسوخ شوند یا کنار گذاشته شوند، خودداری کنید و تنها داده‌های مورد نیاز برای عملیات در حال انجام را واکشی نمایید.

به جای دریافت تمام ستون‌های یک جدول و سپس فیلتر کردن آن‌ها، فقط ستون‌های مورد نیاز خود را از پایگاه داده انتخاب (select) کنید.

به طور مشابه، عملیات تجمعی (aggregation) را در پایگاه داده انجام دهید، نه در حافظه اپلیکیشن.

هنگام استفاده از Entity Framework، اطمینان حاصل کنید که کوئری‌های LINQ با استفاده از اینترفیس `IQueryable` و نه `IEnumerable`، اجرا می‌شوند. ممکن است لازم باشد کوئری خود را طوری تغییر دهید که تنها از توابعی استفاده کند که قابل نگاشت به منبع داده هستند. مثال قبلی را می‌توان با حذف متد `AddDays` از کوئری، بازنویسی (refactor) کرد تا فیلترسازی توسط پایگاه داده انجام شود.

#### **ملاحظات**

در برخی موارد، می‌توان با پارتیشن‌بندی افقی داده‌ها، عملکرد را بهبود بخشید. اگر عملیات‌های مختلف به ویژگی‌های متفاوتی از داده‌ها دسترسی دارند، پارتیشن‌بندی افقی ممکن است رقابت بر سر منابع (contention) را کاهش دهد. اغلب، بیشتر عملیات‌ها روی زیرمجموعه کوچکی از داده‌ها اجرا می‌شوند، بنابراین توزیع این بار کاری می‌تواند عملکرد را بهبود بخشد. به بخش «پارتیشن‌بندی داده‌ها» مراجعه کنید.

برای عملیات‌هایی که باید از کوئری‌های نامحدود (unbounded queries) پشتیبانی کنند، صفحه‌بندی (pagination) را پیاده‌سازی کرده و هر بار تنها تعداد محدودی از موجودیت‌ها را واکشی کنید. برای مثال، اگر مشتری در حال مرور کاتالوگ محصولات است، می‌توانید در هر صفحه، بخشی از نتایج را نمایش دهید.

در صورت امکان، از قابلیت‌های داخلی انبار داده (data store) استفاده کنید. برای مثال، پایگاه‌های داده SQL معمولاً توابع تجمعی (aggregate functions) را ارائه می‌دهند.

اگر از یک انبار داده استفاده می‌کنید که از قابلیت خاصی (مانند aggregation) پشتیبانی نمی‌کند، می‌توانید نتیجه محاسبه‌شده را در جای دیگری ذخیره کرده و با هر بار افزودن یا به‌روزرسانی رکوردها، آن مقدار را نیز به‌روز کنید. به این ترتیب، اپلیکیشن نیازی به محاسبه مجدد آن در هر بار استفاده نخواهد داشت.

اگر متوجه شدید که درخواست‌ها تعداد زیادی فیلد را بازیابی می‌کنند، کد منبع را بررسی کنید تا مشخص شود آیا همه این فیلدها ضروری هستند یا خیر. گاهی اوقات این درخواست‌ها نتیجهٔ یک کوئری `SELECT *` با طراحی ضعیف هستند.

به طور مشابه، درخواست‌هایی که تعداد زیادی موجودیت را بازیابی می‌کنند، ممکن است نشانه‌ای از این باشند که اپلیکیشن داده‌ها را به درستی فیلتر نمی‌کند. بررسی کنید که آیا همه این موجودیت‌ها مورد نیاز هستند. در صورت امکان از فیلترسازی در سمت پایگاه داده استفاده کنید، برای مثال، با استفاده از عبارت `WHERE` در SQL.

واگذاری پردازش به پایگاه داده همیشه بهترین گزینه نیست. تنها زمانی از این استراتژی استفاده کنید که پایگاه داده برای انجام این کار طراحی یا بهینه‌سازی شده باشد. اکثر سیستم‌های پایگاه داده برای توابع خاصی بسیار بهینه‌سازی شده‌اند، اما برای ایفای نقش به عنوان یک موتور کاربردی همه‌منظوره (general-purpose application engine) طراحی نشده‌اند. برای اطلاعات بیشتر، به ضدالگوی «پایگاه داده پرمشغله» (Busy Database) مراجعه کنید.

#### **چگونه ضدالگوی واکشی بی‌رویه را شناسایی کنیم؟**

علائم واکشی بی‌رویه شامل تأخیر بالا (high latency) و توان عملیاتی پایین (low throughput) است. اگر داده‌ها از یک انبار داده بازیابی شوند، افزایش رقابت بر سر منابع (contention) نیز محتمل است. کاربران نهایی احتمالاً زمان پاسخ‌دهی طولانی یا خطاهایی ناشی از پایان زمان مجاز سرویس‌ها (timeout) را گزارش خواهند داد. این خطاها می‌توانند به صورت HTTP 500 (Internal Server Error) یا HTTP 503 (Service Unavailable) بازگردانده شوند. لاگ‌های رویداد وب‌سرور را بررسی کنید، زیرا احتمالاً حاوی اطلاعات دقیق‌تری درباره علل و شرایط خطاها هستند.

علائم این ضدالگو و برخی از داده‌های تله‌متری (telemetry) به‌دست‌آمده، ممکن است بسیار شبیه به علائم ضدالگوی «پایداری یکپارچه» (Monolithic Persistence) باشد.

برای شناسایی علت، می‌توانید مراحل زیر را انجام دهید:

1.  با انجام تست بار (load-testing)، نظارت بر فرآیندها (process monitoring) یا روش‌های دیگر جمع‌آوری داده، بار کاری یا تراکنش‌های کند را شناسایی کنید.
2.  الگوهای رفتاری سیستم را مشاهده کنید. آیا محدودیت‌های خاصی در تعداد تراکنش در ثانیه یا حجم کاربران وجود دارد؟
3.  نمونه‌های کندی بار کاری را با الگوهای رفتاری سیستم مرتبط کنید.
4.  انبارهای داده مورد استفاده را شناسایی کنید. برای هر منبع داده، تله‌متری سطح پایین‌تری را برای مشاهده رفتار عملیات‌ها اجرا کنید.
5.  کوئری‌های کندی را که به این منابع داده ارجاع می‌دهند، شناسایی کنید.
6.  یک تحلیل مبتنی بر منابع (resource-specific analysis) برای کوئری‌های کند انجام دهید و نحوه استفاده و مصرف داده‌ها را مشخص کنید.

به دنبال هر یک از این علائم باشید:
*   درخواست‌های ورودی/خروجی مکرر و بزرگ به یک منبع یا انبار داده یکسان.
*   رقابت (contention) در یک منبع یا انبار داده مشترک.
*   عملیاتی که به طور مکرر حجم زیادی از داده را از طریق شبکه دریافت می‌کند.
*   اپلیکیشن‌ها و سرویس‌هایی که زمان قابل توجهی را در انتظار تکمیل عملیات ورودی/خروجی سپری می‌کنند.

#### **مثال تشخیصی**

بخش‌های زیر این مراحل را برای مثال‌های قبلی به کار می‌گیرند.

##### **شناسایی بارهای کاری کند**
این نمودار نتایج عملکرد یک تست بار را نشان می‌دهد که تا ۴۰۰ کاربر همزمان را برای اجرای متد `GetAllFieldsAsync` (که قبلاً نمایش داده شد) شبیه‌سازی می‌کند. با افزایش بار، توان عملیاتی به آرامی کاهش می‌یابد و میانگین زمان پاسخ‌دهی با افزایش بار کاری، بالا می‌رود.

[نمودار ۱]

---

یک تست بار برای عملیات `AggregateOnClientAsync` الگوی مشابهی را نشان می‌دهد. حجم درخواست‌ها نسبتاً پایدار است. میانگین زمان پاسخ‌دهی با افزایش بار کاری، افزایش می‌یابد، هرچند کندتر از نمودار قبلی.

[نمودار ۲]

---

##### **مرتبط‌سازی بارهای کاری کند با الگوهای رفتاری**

هرگونه ارتباط بین دوره‌های استفاده بالا و کاهش عملکرد می‌تواند نشان‌دهنده نقاط نگران‌کننده باشد. پروفایل عملکرد بخشی که مشکوک به کندی است را به دقت بررسی کنید تا مشخص شود آیا با نتایج تست بار انجام‌شده مطابقت دارد یا خیر.

همان بخش را با استفاده از بارهای کاربری پله‌ای (step-based user loads) تست بار کنید تا نقطه‌ای را پیدا کنید که عملکرد به طور قابل توجهی کاهش می‌یابد یا به طور کامل از کار می‌افتد. اگر آن نقطه در محدوده استفاده واقعی مورد انتظار شما قرار می‌گیرد، نحوه پیاده‌سازی آن بخش را بررسی کنید.

یک عملیات کند لزوماً یک مشکل نیست، به شرطی که زمانی که سیستم تحت فشار است اجرا نشود، از نظر زمانی حیاتی نباشد و بر عملکرد سایر عملیات‌های مهم تأثیر منفی نگذارد. برای مثال، تولید آمار عملیاتی ماهانه ممکن است یک عملیات طولانی باشد، اما احتمالاً می‌توان آن را به عنوان یک فرآیند دسته‌ای (batch process) و با اولویت پایین اجرا کرد. از سوی دیگر، جستجوی مشتریان در کاتالوگ محصولات یک عملیات تجاری حیاتی است. بر روی داده‌های تله‌متری تولیدشده توسط این عملیات‌های حیاتی تمرکز کنید تا ببینید عملکرد در دوره‌های استفاده بالا چگونه تغییر می‌کند.

##### **شناسایی منابع داده در بارهای کاری کند**

اگر مشکوک هستید که یک سرویس به دلیل نحوه بازیابی داده‌ها عملکرد ضعیفی دارد، نحوه تعامل اپلیکیشن با مخازن (repositories) مورد استفاده‌اش را بررسی کنید. سیستم در حال اجرا را نظارت کنید تا ببینید در دوره‌های عملکرد ضعیف، به کدام منابع دسترسی پیدا می‌شود.

برای هر منبع داده، سیستم را ابزار دقیق‌سنجی (instrument) کنید تا موارد زیر را ثبت کند:
*   تعداد دفعات دسترسی به هر انبار داده.
*   حجم داده‌های ورودی و خروجی از انبار داده.
*   زمان‌بندی این عملیات‌ها، به ویژه تأخیر (latency) درخواست‌ها.
*   ماهیت و نرخ هرگونه خطایی که هنگام دسترسی به هر انبار داده تحت بار معمولی رخ می‌دهد.

این اطلاعات را با حجم داده‌ای که توسط اپلیکیشن به کلاینت بازگردانده می‌شود، مقایسه کنید. نسبت حجم داده بازگشتی از انبار داده به حجم داده بازگشتی به کلاینت را ردیابی کنید. اگر اختلاف زیادی وجود دارد، بررسی کنید که آیا اپلیکیشن در حال واکشی داده‌هایی است که به آن‌ها نیازی ندارد.

شما می‌توانید این داده‌ها را با مشاهده سیستم در حال اجرا و ردیابی چرخه عمر هر درخواست کاربر ثبت کنید، یا می‌توانید مجموعه‌ای از بارهای کاری مصنوعی را مدل‌سازی کرده و آن‌ها را بر روی یک سیستم آزمایشی اجرا کنید.

نمودارهای زیر تله‌متری ثبت‌شده با استفاده از New Relic APM در طول یک تست بار برای متد `GetAllFieldsAsync` را نشان می‌دهند. به تفاوت بین حجم داده‌های دریافتی از پایگاه داده و پاسخ‌های HTTP مربوطه توجه کنید.

[نمودار ۳]

---

برای هر درخواست، پایگاه داده ۸۰,۵۰۳ بایت برگردانده است، اما پاسخ به کلاینت تنها حاوی ۱۹,۸۵۵ بایت بوده که حدود ۲۵٪ از حجم پاسخ پایگاه داده است. اندازه داده بازگشتی به کلاینت بسته به فرمت آن می‌تواند متفاوت باشد. برای این تست بار، کلاینت داده‌های JSON درخواست کرده بود. یک تست جداگانه با استفاده از XML (که در اینجا نشان داده نشده) حجم پاسخ ۳۵,۶۵۵ بایت یا ۴۴٪ از حجم پاسخ پایگاه داده را داشت.

تست بار برای متد `AggregateOnClientAsync` نتایج بسیار شدیدتری را نشان می‌دهد. در این حالت، هر تست یک کوئری اجرا کرد که بیش از ۲۸۰ کیلوبایت داده از پایگاه داده بازیابی کرد، اما پاسخ JSON تنها ۱۴ بایت بود. این اختلاف زیاد به این دلیل است که متد یک نتیجه تجمعی را از حجم زیادی از داده‌ها محاسبه می‌کند.

[نمودار ۴]

---

##### **شناسایی و تحلیل کوئری‌های کند**

به دنبال کوئری‌های پایگاه داده‌ای باشید که بیشترین منابع را مصرف می‌کنند و بیشترین زمان را برای اجرا نیاز دارند. می‌توانید ابزارهایی برای ثبت زمان شروع و پایان بسیاری از عملیات‌های پایگاه داده اضافه کنید. بسیاری از انبارهای داده نیز اطلاعات عمیقی در مورد نحوه اجرا و بهینه‌سازی کوئری‌ها ارائه می‌دهند. برای مثال، پنل Query Performance در پورتال مدیریت Azure SQL Database به شما امکان می‌دهد یک کوئری را انتخاب کرده و اطلاعات دقیق عملکرد زمان اجرا را مشاهده کنید. در زیر، کوئری تولیدشده توسط عملیات `GetAllFieldsAsync` آمده است:

[کوئری SQL]

---

##### **پیاده‌سازی راه‌حل و تأیید نتیجه**

پس از تغییر متد `GetRequiredFieldsAsync` برای استفاده از یک دستور `SELECT` در سمت پایگاه داده، تست بار نتایج زیر را نشان داد.

[نمودار ۵]

---

این تست بار از همان زیرساخت استقرار و همان بار کاری شبیه‌سازی‌شده با ۴۰۰ کاربر همزمان استفاده کرد. نمودار تأخیر بسیار کمتری را نشان می‌دهد. زمان پاسخ‌دهی با افزایش بار به حدود ۱.۳ ثانیه می‌رسد، در حالی که در حالت قبل ۴ ثانیه بود. توان عملیاتی نیز با ۳۵۰ درخواست در ثانیه در مقایسه با ۱۰۰ درخواست قبلی، بالاتر است. حجم داده‌های بازیابی‌شده از پایگاه داده اکنون با اندازه پیام‌های پاسخ HTTP تطابق نزدیکی دارد.

[نمودار ۶]

---

تست بار با استفاده از متد `AggregateOnDatabaseAsync` نتایج زیر را تولید می‌کند:

[نمودار ۷]

---

میانگین زمان پاسخ‌دهی اکنون حداقل است. این یک بهبود چشمگیر در عملکرد است که عمدتاً به دلیل کاهش شدید ورودی/خروجی از پایگاه داده ایجاد شده است.

در زیر تله‌متری مربوط به متد `AggregateOnDatabaseAsync` آمده است. مقدار داده‌های بازیابی‌شده از پایگاه داده به شدت کاهش یافته است، از بیش از ۲۸۰ کیلوبایت در هر تراکنش به ۵۳ بایت. در نتیجه، حداکثر تعداد درخواست پایدار در دقیقه از حدود ۲,۰۰۰ به بیش از ۲۵,۰۰۰ افزایش یافته است.

[نمودار ۸]

---

#### **منابع مرتبط**
*   ضدالگوی پایگاه داده پرمشغله (Busy Database)
*   ضدالگوی ورودی/خروجی پُرگو (Chatty I/O)
*   بهترین شیوه‌ها در پارتیشن‌بندی داده‌ها
