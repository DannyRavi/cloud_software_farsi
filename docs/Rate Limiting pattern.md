بسیاری از سرویس ها برای کنترل منابع مورد مصرف از یک الگوی [throttling ](https://learn.microsoft.com/en-us/azure/architecture/patterns/throttling) استفاده می کنند و محدودیت هایی را برای نرخ دسترسی سایر برنامه ها یا سرویس‌ها به آنها تحمیل می کنند. پس میتوانید از یک الگوی محدود کننده نرخ (rate limit) استفاده کنید تا به شما در جلوگیری یا به حداقل رساندن خطاهای مربوط به throttling و  پیش بینی دقیق‌تر توان عملیاتی کمک کند.  
  
الگوی rate limit در بسیاری از سناریوها مناسب است. به ویژه برای تسک‌های خود تکرار شونده که در مقیاس بزرگی فعالیت می‌کنند مانند پردازش دسته‌ای (batch processing) مفید است.

## **طرح صورت مسئله:**

انجام تعداد زیادی عملیات با استفاده از یک سرویس throttled می‌تواند منجر به افزایش ترافیک و توان عملیاتی شود، زیرا باید درخواست‌های رد شده را ردیابی کنید و سپس دوباره آن عملیات را retry یا تست کنید. با افزایش تعداد عملیات‌ها، یک throttling limit ممکن است چندین دفعه ارسال مجدد داد‌ه‌ها را نیاز داشته باشد که منجر به افزایش کارایی می شود.  
  
به عنوان مثال، retryهای ساده زیر را در مورد فرآیند خطا برای وارد کردن داده‌ها به Azure Cosmos DB در نظر بگیرید:

1- برنامه شما باید 10000 رکورد را در Azure Cosmos DB وارد کند. دریافت هر رکورد 10 واحد درخواست یا واحدهای درخواستی (Request Units) یا به خاتصار RUs هزینه دارد که در مجموع به 100000 RU برای تکمیل کردن این کار نیاز دارد.
2- نمونه Azure Cosmos DB شما دارای 20000 RU ظرفیت تدارک دیده شده است.
3- شما تمام 10000 رکورد را به Azure Cosmos DB ارسال می کنید. 2000 رکورد با موفقیت نوشته شده و 8000 رکورد ثبت شده است.
4- شما 8000 رکورد باقیمانده را به Azure Cosmos DB ارسال می کنید. 2000 رکورد با موفقیت نوشته شده و 6000 رکورد ثبت شده است.
5- شما 6000 رکورد باقیمانده را به Azure Cosmos DB ارسال می کنید. 2000 رکورد با موفقیت نوشته شده و 4000 رکورد ثبت شده است.
6- شما 4000 رکورد باقیمانده را به Azure Cosmos DB ارسال می کنید. 2000 رکورد با موفقیت نوشته شده و 2000 رکورد ثبت شده است.
7- شما 2000 رکورد باقیمانده را به Azure Cosmos DB ارسال می کنید. همه با موفقیت نوشته شده اند.


کار وارد کردن داده‌ها با موفقیت انجام شد، اما تنها پس از ارسال 30000 رکورد به Azure Cosmos DB حتی اگر کل مجموعه فقط از 10000 رکورد تشکیل شده بود.

در مثال بالا عوامل دیگری وجود دارد که باید در نظر گرفته شود:  
  
* تعداد زیادی خطا همچنین می تواند منجر به کار اضافی برای ثبت این خطاها و پردازش داده های هزینه از حاصل logها  شود. این رویکرد ساده  20000 خطا را مدیریت کرده است و log این خطاها ممکن است، سربار پردازشی به حافظه یا منبع ذخیره سازی را تحمیل کند.  
* این رویکرد ساده‌ی دیگر، بدون دانستن در مورد محدودیت throttling  سرویس دریافت این است که راهی برای تعیین انتظارات برای مدت زمان پردازش داده‌ها را ندارد. در نتیجه Rate limit می تواند به شما این امکان را دهد که زمان مورد نیاز برای وارد کردن داده ‌ها را محاسبه کنید.

## راه حل

محدودیت نرخ یا Rate limit می تواند ترافیک شما را کاهش دهد و با کاهش تعداد رکوردهای ارسال شده به یک سرویس در یک دوره زمانی معین، به طور محسوسی توان عملیاتی را بهبود بخشد.  
  
یک سرویس ممکن است بر اساس معیارهای مختلف در طول زمان throttle شود، مانند:

* تعداد عملیات‌ها (مثلاً 20 درخواست در ثانیه).  
* مقدار داده‌ها (مثلاً 2 گیگابایت در دقیقه).  
* هزینه‌های مالی نسبی عملیات (به عنوان مثال، 20000 ریال در ثانیه).

صرف نظر از معیاری که برای throttling استفاده می شود، اجرای rate limit شامل کنترل تعداد یا اندازه عملیات ارسال شده به سرویس در یک بازه زمانی خاص و بهینه سازی استفاده شما از سرویس در حالی که از ظرفیت throttling آن از حد مورد انتظار فراتر نمی رود، خواهد بود.  
  
در سناریوهایی که APIهای شما می‌توانند درخواست‌ها را سریع‌تر از هر سرویس دریافتی throttle شده انجام دهند، بهتر است سرعت استفاده از این سرویس را مدیریت کنید. با این حال، تنها در نظر گرفتن throttling به عنوان یک راه حل برای مشکلاتی که در عدم تطابق نرخ داده‌ها و  بافر یا هدایت کردن درخواست‌ها تا زمانی که سرویس throttled بتواند به آن رسیدگی کند تا حدودی خطرناک است. اگر برنامه شما در این سناریو دچار مشکل شود، خطر از دست دادن هر یک از این داده های بافر یا هدایت شده را دارید.

برای جلوگیری از این خطر، رکوردهای خود را به یک سیستم پیام رسانی (messaging) بفرستید که بتواند میزان مصرف کامل داد‌ه‌ها در سرویس شما را کنترل کند. (سرویس هایی مانند Azure Event Hubs می توانند میلیون ها عملیات را در ثانیه انجام دهند). سپس می‌توانید از یک یا چند پردازشگر  برای خواندن رکوردها از سیستم پیام‌رسانی با نرخ کنترل‌شده‌ای استفاده کنید که در محدوده‌های سرویس throttled است. ارسال رکوردها به messaging system می‌تواند میزان مصرف حافظه داخلی را بهینه کند و به شما امکان می‌دهد که فقط رکوردهایی را که در یک بازه زمانی معین پردازش می‌شوند را بعد از پردازش حذف کنید.  
  
Azure چندین سرویس پیام رسانی بادوام ارائه می دهد که می توانید با این الگو از آنها استفاده کنید، از جمله:

- [Azure Service Bus](https://azure.microsoft.com/services/service-bus/)
- [Azure Queue Storage](https://azure.microsoft.com/services/storage/queues/)
- [Azure Event Hubs](https://azure.microsoft.com/services/event-hubs/)

![rate-limiting-pattern-01](../assets/other/rate-limiting-pattern-01.png)

وقتی رکوردها را ارسال می کنید، ممکن است دوره زمانی که برای انتشار رکوردها استفاده می کنید  نسبت به دوره زمانی که از سرویس throttle می گذرد دقیق تر باشد. سیستم‌ها اغلب throttle را بر اساس بازه‌های زمانی تنظیم می‌کنند که به راحتی می‌توانید آن را درک کرده و با آن کار کنید. با این حال، برای رایانه ای که یک سرویس را اجرا می کند، این بازه های زمانی ممکن است در مقایسه با سرعت پردازش اطلاعات بسیار طولانی باشد. به عنوان مثال، یک سیستم ممکن است در هر ثانیه یا در دقیقه throttle شود، اما معمولاً  این کد در حدود نانوثانیه یا میلی‌ثانیه پردازش می‌شود.  


در حالی که ضروری نیست ولی توصیه می شود برای بهبود توان عملیاتی، مقادیر کمتری از رکوردها را به دفعات بیشتر ارسال کنید. پس به جای اینکه بخواهید یک بار در ثانیه یا یک بار در دقیقه موارد مورد نظر را به صورت دسته‌ای منتشر کنید، می‌توانید برای حفظ میزان مصرف منابع خود (حافظه، CPU، شبکه و غیره) با سرعت یکنواخت‌تر عمل کنید و از به وقوع پیوستن گلوگاه در سیستم جلوگیری کنید. به عنوان مثالی برای حجوم درخواست‌های لحظه‌ای، اگر یک سرویس اجازه 100 عملیات در ثانیه را بدهد، پیاده سازی یک محدود کننده نرخ (rate limiter) ممکن است درخواست ها را با آزاد کردن 20 عملیات در هر 200 میلی ثانیه یکسان کند، همانطور که در نمودار زیر نشان داده شده است.

![rate-limiting-pattern-02](../assets/other/rate-limiting-pattern-02.png)


علاوه بر این، گاهی اوقات لازم است چندین فرآیند ناهماهنگ یک سرویس را به اشتراک بگذارند. برای پیاده سازی محدودیت نرخ در این سناریو، می توانید به طور منطقی ظرفیت سرویس را تقسیم بندی کنید و سپس از یک سیستم حذف متقابل توزیع شده برای مدیریت قفل های انحصاری روی آن پارتیشن ها استفاده کنید. سپس فرآیندهای ناهماهنگ می توانند هر زمان که به ظرفیت نیاز داشته باشند برای قفل کردن آن پارتیشن ها رقابت کنند. برای هر پارتیشنی که یک فرآیند برای آن قفل نگه می دارد، مقدار مشخصی ظرفیت به آن داده می شود.  
  
به عنوان مثال، اگر سیستم throttled حدود 500 درخواست در ثانیه را اجازه دهد، ممکن است شما 20 پارتیشن به ارزش 25 درخواست در هر ثانیه ایجاد کنید. اگر فرآیندی نیاز به صدور 100 درخواست داشته باشد، ممکن است از سیستم ممانعت متقابل توزیع شده (distributed mutual exclusion) برای چهار پارتیشن دیگر درخواست کند. درنتیجه ممکن است سیستم دو پارتیشن به مدت 10 ثانیه را در دسترس قرار دهد. سپس این فرآیند به 50 درخواست در ثانیه محدودیت نرخ یا rate limit می دهد و تسک را در دو ثانیه انجام می دهد و سپس قفل را آزاد می کند.


یکی از راه‌های پیاده‌سازی این الگو، استفاده از Azure Storage است. در این سناریو، شما یک حباب(blob) یه مقدار 0 بایتی برای هر پارتیشن منطقی در یک ظرف ایجاد می کنید. سپس برنامه‌های شما می‌توانند مستقیماً برای مدت کوتاهی (مثلاً 15 ثانیه) در برابر آن حباب‌ها قراردادهای انحصاری([exclusive leases](https://learn.microsoft.com/en-us/rest/api/storageservices/lease-blob)) دریافت کنند. برای هر قرارداد که یک برنامه اعطا می شود، می تواند از ظرفیت آن پارتیشن استفاده کند. سپس برنامه باید زمان قرارداد را ردیابی کند تا پس از انقضای آن، بتواند از ظرفیتی که داده شده است دیگر استفاده نکند. هنگام پیاده‌سازی این الگو، معمولا می‌خواهیم که هر فرآیند زمانی که به ظرفیت خاصی نیاز دارد، سعی کند یک پارتیشن تصادفی قرارداد کند.  
  
برای کاهش بیشتر تاخیر، ممکن است مقدار کمی از ظرفیت انحصاری را برای هر فرآیند اختصاص دهید. در این صورت یک فرآیند تنها در صورتی به دنبال دریافت قرارداد ظرفیت مشترک است که نیاز به فراتر رفتن از ظرفیت رزرو شده خود داشته باشد.

![rate-limiting-pattern-03](../assets/other/rate-limiting-pattern-03.png)

به عنوان جایگزینی برای Azure Storage، می‌توانید این نوع سیستم مدیریت قرارداد را با استفاده از فناوری‌هایی مانند [Zookeeper](https://zookeeper.apache.org/), [Consul](https://www.consul.io/), [etcd](https://etcd.io/), [Redis/Redsync](https://github.com/go-redsync/redsync) و غیره پیاده‌سازی کنید.


## مسائل و ملاحظات:

* در حالی که الگوی محدود کننده نرخ می تواند تعداد خطاهای throttling را کاهش دهد، برنامه شما همچنان باید به درستی خطاهای throttling را که ممکن است رخ دهد مدیریت کند.  

* اگر برنامه شما دارای چندین جریان کاری(workstreams) است که به همان سرویس throttled دسترسی دارند، پس باید همه آنها را در استراتژی محدود کردن نرخ خود ادغام کنید. به عنوان مثال، ممکن است از بارگذاری انبوه رکوردها (bulk loading records) در پایگاه داده پشتیبانی کنید اما همزمان از اعمال کوئری روی رکوردها (querying for records) در همان پایگاه داده پشتیبانی کنید. می‌توانید با اطمینان از اینکه همه جریان‌های کاری از طریق مکانیسم محدودکننده نرخ یکسانی عبور می‌کنند، ظرفیت را مدیریت کنید. از طرف دیگر، می توانید ظرفیت های جداگانه ای را برای هر جریان کاری در نظر بگیرید. 

* سرویس throttled ممکن است در چندین برنامه استفاده شود. در برخی - اما نه همه - موارد، می توان نوع مصرف را هدایت کرد (همانطور که در بالا نشان داده شده است). اگر شروع به مشاهده تعداد بیشتر از حد انتظار خطاهای throttling کردید، ممکن است نشانه اختلاف بین برنامه هایی باشد که به یک سرویس دسترسی دارند. اگر چنین است، ممکن است لازم باشد به طور موقت میزان توان اعمال شده توسط مکانیسم محدودکننده نرخ خود را کاهش دهید تا زمانی که استفاده از سایر برنامه ها کاهش یابد.

## **چه زمانی از این الگو استفاده کنیم؟**

از این الگو برای موارد زیر استفاده کنید:  
  
* خطاهای throttling ایجاد شده توسط سرویس محدود throttle-limited را کاهش دهید.  
* کاهش ترافیک در مقایسه با یک روش ساده retry بر روی خطاها.  
* مصرف حافظه را با حذف رکوردها تنها زمانی که ظرفیت پردازش برای آنها وجود دارد، کاهش دهید.

## مثال

برنامه مثال زیر به کاربران اجازه می دهد تا رکوردهایی از انواع مختلف را به یک API ارسال کنند. برای هر نوع رکورد یک پردازشگر کار منحصر به فرد وجود دارد که مراحل زیر را انجام می دهد:  
  
1- اعتبار سنجی  (Validation)
2- غنی سازی  (Enrichment)
3- درج رکورد در پایگاه داده 

همه اجزای برنامه (API، job processor A، و  job processor B ) فرآیندهای جداگانه ای هستند که ممکن است به طور مستقل مقیاس (scale) شوند. فرآیندها مستقیماً با یکدیگر ارتباط برقرار نمی کنند.

![rate-limiting-pattern-04](../assets/other/rate-limiting-pattern-04.png)


1- یک کاربر 10000 رکورد از نوع A را به API ارسال می کند.  
2- API آن 10000 رکورد را در صف A قرار می دهد.  
3- یک کاربر 5000 رکورد از نوع B را به API ارسال می کند.  
4- API آن 5000 رکورد را در صف B قرار می دهد.  
5- Job Processor A می بیند که Queue A دارای رکورد است و سعی می کند یک قرارداد(lease) انحصاری در blob 2 به دست آورد.  
6- Job Processor B می بیند که Queue B دارای رکورد است و سعی می کند یک قرارداد انحصاری در blob 2 به دست آورد.  
7- Job Processor A موفق به دریافت قرارداد نامه نمی شود.  
8- Job Processor B قرارداد blob 2 را به مدت 15 ثانیه دریافت می کند. اکنون می تواند درخواست های محدود به پایگاه داده را با نرخ 100 در ثانیه رتبه بندی کند.  
9- Job Processor B 100 رکورد را از صف B جدا می کند و آنها را می نویسد.  
10- یک ثانیه می گذرد.  
11- Job Processor A می بیند که Queue A رکوردهای بیشتری دارد و سعی می کند قرارداد انحصاری را در blob 6 به دست آورد.  
12- Job Processor B می بیند که Queue B رکوردهای بیشتری دارد و سعی می کند قرارداد انحصاری را در blob 3 به دست آورد.  
13- Job Processor A قرارداد blob 6 را به مدت 15 ثانیه دریافت می کند. اکنون می تواند درخواست های محدود به پایگاه داده را با نرخ 100 در ثانیه رتبه بندی کند.  
14- Job Processor B قرارداد blob 3 را به مدت 15 ثانیه دریافت می کند. اکنون می تواند درخواست‌های محدود به پایگاه داده را با نرخ 200 در ثانیه رتبه بندی کند. (همچنین قرارداد  2 blob را نیز در اختیار دارد.)  
15- Job Processor A 100 رکورد را از صف A جدا می کند و آنها را می نویسد.  
16- Job Processor B 200 رکورد را از صف B جدا می کند و آنها را می نویسد.  
17- یک ثانیه می گذرد.  
18- Job Processor A می بیند که Queue A رکوردهای بیشتری دارد و سعی می کند یک قرارداد انحصاری در blob 0 به دست آورد.  
19- Job Processor B می بیند که Queue B رکوردهای بیشتری دارد و سعی می کند یک قرارداد انحصاری در blob 1 به دست آورد.  
20- Job Processor A قرارداد blob 0 را به مدت 15 ثانیه دریافت می کند. اکنون می تواند درخواست های محدود به پایگاه داده را با نرخ 200 در ثانیه رتبه بندی کند. (همچنین قرارداد blob 6 را نیز دارد.)  
21- Job Processor B قرارداد blob 1 را به مدت 15 ثانیه دریافت می کند. اکنون می تواند درخواست های محدود به پایگاه داده را با نرخ 300 در ثانیه رتبه بندی کند. (همچنین قرارداد blob 2 و 3 را نیز دارد.)  
22- Job Processor A 200 رکورد را از صف A جدا می کند و آنها را می نویسد.  
23- Job Processor B 300 رکورد را از صف B جدا می کند و آنها را می نویسد.  
24- و غیره...  

پس از 15 ثانیه، یک یا هر دو کار هنوز تکمیل نخواهد شد. همانطور که قراردادها(leases) منقضی می‌شوند، یک پردازنده باید تعداد درخواست‌هایی را که می‌نویسد و (متفرق) dequeue میکند را نیز کاهش دهد.  
  
پیاده سازی این الگو که در Go پیاده سازی شده است در [GitHub](https://github.com/mspnp/go-batcher) موجود است و همینطور پیاده سازی جاوا در [GitHub](https://github.com/Azure-Samples/java-rate-limiting-pattern-sample) در دسترس است.

## منابع مرتبطت

الگوها و راهنمایی‌های زیر نیز ممکن است هنگام اجرای این الگو مرتبط باشند:  
  
* الگوی [Throttling](https://learn.microsoft.com/en-us/azure/architecture/patterns/throttling). الگوی محدود کننده نرخ که در اینجا مورد بحث قرار می‌گیرد، معمولاً در پاسخ به سرویسی اجرا می‌شود.  
* الگوی [Retry](https://learn.microsoft.com/en-us/azure/architecture/patterns/retry). هنگامی که درخواست‌ها برای سرویس throttle شده منجر به خطاهای throttling می‌شوند، معمولاً مناسب است که پس از یک بازه زمانی مناسب دوباره آن‌ها را retry کنید.  

این الگو با الگوی سطح بندی بار مبتنی بر صف ([Queue-Based Load Leveling](https://learn.microsoft.com/en-us/azure/architecture/patterns/queue-based-load-leveling)) مشابه است اما از چند جهت کلیدی با الگوی محدود کردن نرخ که در این قسمت بیان شد متفاوت است:

1- محدود کردن نرخ (Rate limiting) لزوماً نیازی به استفاده از صف برای مدیریت بار ندارد، اما نیاز به استفاده از یک سرویس پیام رسانی بادوام دارد. به عنوان مثال، یک الگوی محدود کننده نرخ می تواند از سرویس هایی مانند  Apache Kafka یا Azure Event Hubs استفاده کند.  

2- الگوی محدود کننده نرخ، مفهوم یک سیستم ممانعت متقابل توزیع شده (distributed mutual exclusion) را در پارتیشن ها معرفی می کند، که به شما امکان می دهد ظرفیت چندین فرآیند ناهماهنگ را که با یک سرویس throttle شده ارتباط برقرار می کنند را مدیریت کنید.

3- یک الگوی queue-based load leveling در هر زمان که عدم تطابق کارکرد بین سرویس‌ها یا  بهبود انعطاف‌پذیری وجود داشته باشد، قابل اجرا است. این مورد باعث می‌شود که الگوی گسترده‌تری نسبت به محدود کردن نرخ، که به طور خاص به دسترسی موثر به یک سرویس throttle شده می‌پردازد، را داشته باشد.

